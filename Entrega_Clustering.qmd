---
title: "Clustering"
author: "Xisco Ribera & Irene Julià"
format:
  html:
    toc: true
    toc-depth: 5
editor: visual
---

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(dplyr)
library(GGally)
library(psych)
library(skimr)
library(fmsb)
library(mvnormtest)
library(car)
library(nortest)
library(fBasics)
library(ggplot2)
library(factoextra)
library(stats)
library(cluster)
library(NbClust)
library(ggrepel)
```

# Recordatorio

Vamos a tratar una base de datos relacionados con la predicción de riesgo de cirrosis. La cirrosis es una etapa tardía de la cicatrización (fibrosis) del hígado causada por muchas formas de enfermedades y afecciones hepáticas, como la hepatitis y el alcoholismo crónico.

Nuestro objetivo para este estudio sería estudiar algunos perfiles con riesgo de padecer cirrosis.

Recordemos nuestra tabla de datos:

```{r}
datos <- read.table("cirrosis_tidy.csv",  header = TRUE )
datos = datos %>% mutate(Ascites = Ascites %>% as.factor,
                         Hepatomegaly = Hepatomegaly %>% as.factor,
                         Spiders = Spiders %>% as.factor,
                         Edema = Edema %>% as.factor,
                         Stage = Stage %>% as.factor,
                         Drug = Drug %>% as.factor,
                         Sex = Sex %>% as.factor,
                         Status = Status %>% as.factor)


glimpse(datos)
```

El tibble resultante consta de 276 observaciones y 20 variables. Cada muestra representa un paciente al que se le ha extraido la siguiente información:

-   `ID`: Identificador único
-   `N_Days`: Número de días entre el registro y la fecha de defunción, transplante o estudio analítico en Julio de 1986.
-   `Status`: Estatus del paciente: C (Censurado), CL (censurado debido a tratamiento hepático), o D (Muerto)
-   `Drug`: Tipo de fármaco: D-penicilamina o placebo
-   `Age`: Edad \[días\]
-   `Sex`: Sexo cromosómico: Male (hombre) o Female (Mujer)
-   `Ascites`: Presencia de Ascitis: No o Si
-   `Hepatomegaly`: Presencia de Hepatomegalia: No o Si
-   `Spiders`: Presencia de arañas vasculares: No o Si
-   `Edema`: Presencia de Edema: No (no hay edema y sin tratamiento diurético para el edema), Sin (presencia de edema sin diuréticos, o edema curado con diuréticos), o Si (edema a pesar del tratamiento con diuréticos)
-   `Bilirubin`: Bilirrubina sérica \[mg/dl\]
-   `Cholesterol`: Colesterol sérico \[mg/dl\]
-   `Albumin`: Albúmina \[g/dl\]
-   `Copper`: Cobre en orina \[ug/day\]
-   `Alk_Phos`: Fosfatasa alcalina \[U/liter\]
-   `SGOT`: SGOT \[U/ml\]
-   `Triglycerides`: Triglicéridos \[mg/dl\]
-   `Platelets`: Plaquetas por cúbico \[ml/1000\]
-   `Prothrombin`: Tiempo de Protrombina \[s\]
-   `Stage`: Estado histórico de la enfermedad (1, 2, 3, or 4)

## Resumen numérico de las variables

-   Datos cuantitativos:

```{r, echo=FALSE}
# Separamos los datos en variables cuantitativas y cualitativas
datos_quant <- datos %>% 
  select(where(is.numeric)) %>% 
  select(-1)


datos_qual <- datos %>% 
  select(where(is.factor))


# Cuantitativas

Unidad = c("Días", "Días", "mg/dl", "mg/dl", "g/dl", "ug/día", "U/l", "U/ml", "mg/dl", "ml/1000", "s")

Media = round(colMeans(datos_quant),3)

rango <- function(x){
  return(max(x)-min(x))
}
Rango = round(apply(datos_quant, FUN = rango, MARGIN = 2), 3)
Minimo = round(apply(datos_quant, FUN = min, 2),3)
Maximo = round(apply(datos_quant, FUN = max, 2),3)
Desv = round(apply(datos_quant, FUN = sd, 2), 3)

tabla = data.frame(Unidad, Media, Desv, Minimo, Maximo, Rango)

tabla
```

-   Datos cualitativos:

```{r, echo=FALSE}
summary(datos_qual)
```

## Análisis de normalidad multivariante

Con estos datos vamos a realizar nuestro estudio de normalidad multivariante.

Calculemos el vector de medias

```{r, echo = FALSE}
Medias = colMeans(datos_quant) # vector de medias

S = cov(datos_quant) # matriz de covarianza
```

y la distancia de Mahalanobis:

```{r}
d_Mahalanobis = apply(datos_quant, MARGIN = 1, function(x)
                    t(x - Medias)%*%solve(S)%*%(x - Medias))
```

Una vez calculadas estas medidas, representemos los datos

```{r, echo=FALSE}
plot(qchisq((1:nrow(datos_quant) - 1/2) / nrow(datos_quant), df = 3), sort(d_Mahalanobis), xlab = expression(paste("Cuantiles de la ", chi[20]^2)),ylab="Distancias ordenadas")
abline(a=0,b=1)
```

Notemos que no sigue una Chi-cuadrado, i por tanto los datos tampoco siguen una normal multivariante.

Vamos a realizar un test de normalidad para confirmarlo. Utilizaremos Shapiro-Wilk:

```{r}
mvnormtest::mshapiro.test(t(datos_quant))
```

Obtenemos un p-valor muy pequeño, prácticamente 0, entonces, rechazamos la hipótesis nula y concluimos que no hay normalidad multivariante, es decir, almenos una variable individual no se distribuye normalmente.





# Clustering

Vamos a guardar en un nuevo dataset las variables cuantitativas. Vamos a tipificar o escalar nuestros datos para que esten todos a la misma escala:

```{r}
datos2 <- datos_quant %>% scale()
```

A continuación, realicemos una representación gráfica de matrices de distancia:

Primero de todo vamos a centrar la matriz de datos:

```{r}
n <- dim(datos2)[1]
X <- as.matrix(datos2)
Hn <- diag(n)-1/n # matriz de centrado
cX <- Hn%*%X # matriz centrada
```

```{r}
mat_dist <- dist(x = cX, method = "euclidean")
```

```{r, cache = TRUE}
fviz_dist(dist.obj = mat_dist, lab_size = 5) +
 theme(legend.position = "none")
```

## K-means

En nuestro caso, no sabemos en cuantos clusters o grupos esta dividido nuestro dataset. Por tanto, vamos a estimar al número $k$ óptimo para aplicar el método de `kmeans()`. Para ello, utilizaremos la función `fviz_nbclust()`:

```{r}
fviz_nbclust(x = cX, FUNcluster = kmeans, method = "wss",
 diss = dist(cX, method = "euclidean"))
```
Realmente, con el método del codo, es un poco complicado establemcer un $k$ óptimo, así que vamos a utilizar otros métodos que nos proporciona `R`:


```{r}
fviz_nbclust(x = cX, FUNcluster = kmeans, method = "silhouette")
```


```{r}
fviz_nbclust(x = cX, FUNcluster = kmeans, method = "gap_stat")
```


Con el método de la silueta, nos sugiere escoger $k=2$, en cambio, con el siguiente, nos sugiere 8 clusters. Como no hemos salido de dudas, vamos a realizar otro experimento: vamos a realizar una función que nos proporciona 30 índices para determinar el número de clusters.

```{r, cache=TRUE,eval=FALSE}
resnumclust = NbClust(data = cX, distance = "euclidean", min.nc = 2, max.nc = 10, 
                      method = "kmeans", index = "alllong")
```


```{r, echo=FALSE}
# fix the functions
fviz_nbclust <- function (x, FUNcluster = NULL, method = c("silhouette", "wss", 
                                           "gap_stat"), diss = NULL, k.max = 10, nboot = 100, verbose = interactive(), 
          barfill = "steelblue", barcolor = "steelblue", linecolor = "steelblue", 
          print.summary = TRUE, ...) 
{
  set.seed(123)
  if (k.max < 2) 
    stop("k.max must bet > = 2")
  method = match.arg(method)
  if (!inherits(x, c("data.frame", "matrix")) & !("Best.nc" %in% 
                                                  names(x))) 
    stop("x should be an object of class matrix/data.frame or ", 
         "an object created by the function NbClust() [NbClust package].")
  if (inherits(x, "list") & "Best.nc" %in% names(x)) {
    best_nc <- x$Best.nc
    if (any(class(best_nc) == "numeric") ) 
      print(best_nc)
    else if (any(class(best_nc) == "matrix") )
      .viz_NbClust(x, print.summary, barfill, barcolor)
  }
  else if (is.null(FUNcluster)) 
    stop("The argument FUNcluster is required. ", "Possible values are kmeans, pam, hcut, clara, ...")
  else if (!is.function(FUNcluster)) {
    stop("The argument FUNcluster should be a function. ", 
         "Check if you're not overriding the specified function name somewhere.")
  }
  else if (method %in% c("silhouette", "wss")) {
    if (is.data.frame(x)) 
      x <- as.matrix(x)
    if (is.null(diss)) 
      diss <- stats::dist(x)
    v <- rep(0, k.max)
    if (method == "silhouette") {
      for (i in 2:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_ave_sil_width(diss, clust$cluster)
      }
    }
    else if (method == "wss") {
      for (i in 1:k.max) {
        clust <- FUNcluster(x, i, ...)
        v[i] <- .get_withinSS(diss, clust$cluster)
      }
    }
    df <- data.frame(clusters = as.factor(1:k.max), y = v, 
                     stringsAsFactors = TRUE)
    ylab <- "Total Within Sum of Square"
    if (method == "silhouette") 
      ylab <- "Average silhouette width"
    p <- ggpubr::ggline(df, x = "clusters", y = "y", group = 1, 
                        color = linecolor, ylab = ylab, xlab = "Number of clusters k", 
                        main = "Optimal number of clusters")
    if (method == "silhouette") 
      p <- p + geom_vline(xintercept = which.max(v), linetype = 2, 
                          color = linecolor)
    return(p)
  }
  else if (method == "gap_stat") {
    extra_args <- list(...)
    gap_stat <- cluster::clusGap(x, FUNcluster, K.max = k.max, 
                                 B = nboot, verbose = verbose, ...)
    if (!is.null(extra_args$maxSE)) 
      maxSE <- extra_args$maxSE
    else maxSE <- list(method = "firstSEmax", SE.factor = 1)
    p <- fviz_gap_stat(gap_stat, linecolor = linecolor, 
                       maxSE = maxSE)
    return(p)
  }
}

.viz_NbClust <- function (x, print.summary = TRUE, barfill = "steelblue", 
          barcolor = "steelblue") 
{
  best_nc <- x$Best.nc
  if (any(class(best_nc) == "numeric") )
    print(best_nc)
  else if (any(class(best_nc) == "matrix") ) {
    best_nc <- as.data.frame(t(best_nc), stringsAsFactors = TRUE)
    best_nc$Number_clusters <- as.factor(best_nc$Number_clusters)
    if (print.summary) {
      ss <- summary(best_nc$Number_clusters)
      cat("* Among all indices: \n===================\n")
      for (i in 1:length(ss)) {
        cat("*", ss[i], "proposed ", names(ss)[i], 
            "as the best number of clusters\n")
      }
      cat("\n \t *****Conclusion*****\n")
      cat("* According to the majority rule, the best number of clusters is ", 
          names(which.max(ss)), ".\n\n")
    }
    df <- data.frame(Number_clusters = names(ss), freq = ss, 
                     stringsAsFactors = TRUE)
    p <- ggpubr::ggbarplot(df, x = "Number_clusters", 
                           y = "freq", fill = barfill, color = barcolor) + 
      labs(x = "Number of clusters k", y = "Frequency among all indices", 
           title = paste0("Optimal number of clusters - k = ", 
                          names(which.max(ss))))
    return(p)
  }
}
# assign them to the factoextra namespace
environment(fviz_nbclust) <- asNamespace("factoextra")
assignInNamespace("fviz_nbclust",fviz_nbclust,"factoextra")
environment(.viz_NbClust) <- asNamespace("factoextra")
assignInNamespace(".viz_NbClust",.viz_NbClust,"factoextra")
```




```{r, cache=TRUE}
fviz_nbclust(resnumclust)
```


Vamos a calcular los 4 clusters con nuestros datos y con 30 iteraciones. Además, vamos a visualizar como ha quedado la partición.

```{r}
#set.seed(2312)
km_clusters <- kmeans(x = cX, centers = 4, nstart = 30)
km_clusters$cluster
```

Ahora bien, representemos dichos clusters en el plano. Como nuestro número de variables (dimensionalidad) es mayor de 2, automáticamente realiza un PCA y representa las dos primeras componentes principales (Dim1 y Dim2)

```{r}
fviz_cluster(object = km_clusters, data = cX, show.clust.cent = TRUE, geom ="point",
 ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
theme_bw() +
theme(legend.position = "none")
```
Como podemos var, al menos en la proyección en 2 dimensiones, hay bastante solapamiento. Además, si vemos la zona pintada como si fuera un intervalo de confianza, hay muchas observaciones que quedan fuera.



```{r, cache =TRUE}
res = hcut(cX, k=4, stand = TRUE)
fviz_dend(res, rect = TRUE, cex = 0.5, k_colors = c("#FF7078", "#F39B4C", "#7FBFF5", "#A298E8"))
```



Ahora bien, sería interesante ver si estos clusters corresponden a las fases de cirrosis segun la variable `stage`.

Vamos a crear un data frame compuesto de 3 columnas: identificador del paciente, estado de la enfermedad y cluster al que pertenece.

```{r}
id_stage = datos %>% 
  select(ID, Stage)
Cluster = km_clusters$cluster %>% as.factor()

tabla_cluster = cbind(id_stage, Cluster)
tabla_cluster

round(100*prop.table(table(x = tabla_cluster[,c(2,3)])), 3)

table(x = tabla_cluster[,c(2,3)])
```
FATAL





## K-medoids (PAM)

En este caso, cada cluster está representado por una observación presente en el cluster (medoid), mientras que en K-means cada cluster está representado por su centroide, que se corresponde con el promedio de todas las observaciones del cluster pero con ninguna en particular.

```{r, warning=FALSE}
fviz_nbclust(x = cX, FUNcluster = pam, method = "wss",
 diss = dist(datos, method = "euclidean")) +
  geom_vline(xintercept = 6, linetype = 2)
```

```{r}
pam_clusters <- pam(x = cX, k = 6, metric = "euclidean")

fviz_cluster(object = pam_clusters, data = cX, ellipse.type = "t", geom = "point",  repel = TRUE) +
  theme_bw() + 
  theme(legend.position = "none")
```

## Dendograma

```{r, cache =TRUE}
set.seed(101)
hc_completo <- datos_quant %>% scale() %>% dist(method = "euclidean") %>%
 hclust(method = "complete")
fviz_dend(x = hc_completo, k = 3, cex = 0.6) +
 geom_hline(yintercept = 10.5, linetype = "dashed")
```



## Análisis de Componentes Principales

Calculamos las componentes principales con el comando `prcomp` utilizando nuestro dataset, sin escalar los datos ya que están todos en la misma escala. Por último, los consideramos centrados en el 0.

```{r}
datos.acp=prcomp(cX, scale = FALSE, center = FALSE)
```

Los valores propios muestran el porcentaje de varianza explicada por cada componente principal.

```{r, echo=FALSE}
lambdas = get_eigenvalue(datos.acp)
round(lambdas, 5)
```



```{r, echo=FALSE}
fviz_eig(datos.acp, addlabels = TRUE, ylim=c(0,100))
```

Efectivamente, viendo el gráfico y utilizando el criterio del codo, nos quedaremos con 

Realicemos un gráfico de círculo de correlación variable para ver como se agrupan las variables y la calidad de representación que tienen.

```{r, echo=FALSE}
fviz_pca_var(datos.acp, axes = c(1,2), col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE)
```



Para corroborar numéricamente la calidad de representación, realizaremos un gráfico de cos2.

```{r, echo=FALSE}
var <- get_pca_var(datos.acp)
fviz_cos2(datos.acp, choice = "var", axes = 1:2)
```

Efectivamente, las tres primeras variables tienen un cos2 alto, por tanto estas bien representadas. En cambio, las otras variables tienen un valor de cos2 prácticamente nulo, indica que estas variables no estan bien representadas por las componentes principales.

Para ver como se relacionan las componentes principales con los datos originales, veamos los autovectores.

```{r, echo=FALSE}
round(datos.acp$rotation,4)
```

Observemos que la primera componente principal da un peso muy elevado y positivo a la variable `Agrucultura`, y de signo contrario a las demás (excepto `Mineria` con un peso muy bajo).

Respecto a la segunda componente principal, representa sobretodo a `Fábrica` y a `Servicios Sociales y Personales` (con signos opuestos pero un peso elevado).

Ahora, vamos a realizar un `biplot`, que nos permitirá visualizar las variables originales y las observaciones transformadas en los ejes de componentes principales.

```{r, echo=FALSE}
fviz_pca_biplot(datos.acp,  repel = TRUE,
                col.var = "#2E9FDF", # color para las variables
                col.ind = "#696969"  # color para las observaciones
                )
```

De nuevo, se aprecia como la variable `Agricultura` es la mejor representada debido a la longitud de la flecha. Le siguen las variables de `Fábricas` y `Servicios Sociales y Personales`, mejor representadas por la segunda componente.

### Resultados del Análisis

Llegado a este punto, vamos a comprobar numéricamente todas las conclusiones que hemos sacado anteriormente. Realmente basta restringirnos a las dos primeras componentes principales ya que en el estudio hemos decidido utilizar solamente estas dos.

#### Resultados por Variables

Empezamos por las contribuciones de las variables a las componentes principales.

```{r, echo=FALSE}
res.var=get_pca_var(datos.acp)
round(res.var$contrib, 4)      # Contribuciones a las CP
```

Tambien apreciamos la calidad de representación de las variables a las componentes principales.

```{r, echo=FALSE}
round(res.var$cos2, 5)
```

Respecto a las variables, hemos podido comprobar lo expuesto anteriormente, se aprecia una fuerte contribución de la variable `Agricultura` a la primera componente principal, además de una muy buena representación (un valor de cos2 muy elevado).

Seguidamente, la variable `Fábricas` tiene gran contribución a la segunda componente principal, con menor representación debido al valor de cos2 y que también contribuye a la primera componente principal, pero muy poco. En cambio, la variable `Servicios sociales y Personales` tiene más poca contribución a la segunda componente, pero está algo mejor representada por la primera que la variable anterior; de todos modos, la calidad de representación es más baja que las anteriores.

No podemos destacar más variables ya que, como vimos en los gráficos, no habia prácticamente representación por parte de las componentes principales.

#### Resultados por Observaciones

Ahora, respecto a las observaciones, empezamos por las coordenadas.

```{r, echo=FALSE}
res.obs=get_pca_ind(datos.acp)
#round(res.obs$coord, 2)  #Coordenadas
head(round(res.obs$coord, 2), 5)  #Coordenadas
```

También las contribuciones de cada observación a las componentes principales.

```{r, echo=FALSE}
#round(res.obs$contrib,2)  #Contribuciones a las CP
head(round(res.obs$contrib,2), 5)  #Contribuciones a las CP
```

Por último, la calidad de representación, es decir, el valor de cos2.

```{r, echo=FALSE}
#round(res.obs$cos2,3)  # Calidad de la representación
head(round(res.obs$cos2,3), 5)
```



```{r, echo=FALSE, eval=FALSE}
autoplot(datos.acp, data = datos, colour = 'Grupo',
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = FALSE, loadings.label.size = 3, size = 3) +
  geom_text_repel(aes(label = rownames(datos)), box.padding = 0.5, segment.color = "darkgrey", size = 3, color = "darkgrey") +
  theme_bw()
```











